# é¡¹ç›®æ¸…ç†å’Œæ›´æ–°æ€»ç»“

## âœ… å®Œæˆçš„å·¥ä½œ

### 1. ç”Ÿæˆæ–°çš„è®­ç»ƒè„šæœ¬

åˆ›å»ºäº†ä¸å½“å‰HLSæ¶æ„(6-8-64)å®Œå…¨åŒ¹é…çš„è®­ç»ƒè„šæœ¬ï¼š

**æ–‡ä»¶**: `tests/mnist/train_model.py`

**ç‰¹æ€§**:
- âœ… æ¶æ„åŒ¹é…: Conv1[6] â†’ Conv2[8] â†’ FC1[64] â†’ FC2[10]
- âœ… é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ (QAT): æ¨¡æ‹Ÿ ap_fixed<16,8>
- âœ… BatchNormèåˆ: è‡ªåŠ¨èåˆåˆ°æƒé‡ä¸­
- âœ… æ•°æ®å¢å¼º: éšæœºå¹³ç§»Â±2åƒç´ 
- âœ… é«˜çº§è®­ç»ƒæŠ€å·§: Dropout, Label Smoothing, Cosine Annealing, Early Stopping
- âœ… è‡ªåŠ¨æƒé‡å¯¼å‡º: å¯¼å‡ºä¸ºHLSå…¼å®¹çš„äºŒè¿›åˆ¶æ ¼å¼
- âœ… è¯¦ç»†æ—¥å¿—: æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œæœ€ä½³ç»“æœ

**å‚æ•°**:
```python
CONV1_OUT_CH = 6
CONV2_OUT_CH = 8
FC1_OUT_SIZE = 64
FC2_OUT_SIZE = 10
æ€»å‚æ•°: ~10,000
```

### 2. æ›´æ–°Makefile

**æ–°å¢ç›®æ ‡**:
```makefile
make mnist_train        # æ ‡å‡†è®­ç»ƒ (60 epochs, ~40åˆ†é’Ÿ)
make mnist_train_quick  # å¿«é€Ÿè®­ç»ƒ (20 epochs, ~15åˆ†é’Ÿ)
make clean_old_scripts  # æ¸…ç†åºŸå¼ƒè„šæœ¬
```

**æ›´æ–°çš„å¸®åŠ©ä¿¡æ¯**:
- æ·»åŠ äº†è®­ç»ƒæ—¶é—´ä¼°è®¡
- æ›´æ¸…æ™°çš„å‘½ä»¤è¯´æ˜
- æ–°å¢æ¸…ç†é€‰é¡¹

### 3. åˆ é™¤åºŸå¼ƒæ–‡ä»¶

å·²åˆ é™¤ä»¥ä¸‹æ—§è®­ç»ƒè„šæœ¬ï¼š
- âŒ `train_mnist.py` (æ—§æ¶æ„)
- âŒ `train_mnist_optimized.py` (4-8-64æ¶æ„)
- âŒ `train_improved.py` (6-12-84æ¶æ„)
- âŒ `train_ultra_optimized.py` (6-10-80æ¶æ„)
- âŒ `train_optimized.sh` (åºŸå¼ƒ)
- âŒ `train_improved.sh` (åºŸå¼ƒ)

**ä¿ç•™çš„æ–‡ä»¶**:
- âœ… `train_model.py` (å½“å‰6-8-64æ¶æ„)
- âœ… `train.sh` (å¿«é€Ÿå¯åŠ¨è„šæœ¬)

### 4. åˆ›å»ºæ–‡æ¡£

**æ–°æ–‡æ¡£**:
- `tests/mnist/TRAINING_README.md` - è¯¦ç»†çš„è®­ç»ƒæŒ‡å—
  - æ¶æ„è¯´æ˜
  - å¿«é€Ÿå¼€å§‹æ­¥éª¤
  - å‚æ•°è¯´æ˜
  - æ•…éšœæ’é™¤
  - ä¸HLSé›†æˆè¯´æ˜

### 5. å¿«é€Ÿå¯åŠ¨è„šæœ¬

**æ–‡ä»¶**: `tests/mnist/train.sh`

ä½¿ç”¨æ–¹æ³•:
```bash
# é»˜è®¤è®­ç»ƒ (60 epochs)
cd tests/mnist
./train.sh

# è‡ªå®šä¹‰epochså’Œbatch size
./train.sh 40 64  # 40 epochs, batch size 64
```

## ğŸ“ å½“å‰æ–‡ä»¶ç»“æ„

```
tests/mnist/
â”œâ”€â”€ train_model.py          â† ä¸»è®­ç»ƒè„šæœ¬ (6-8-64æ¶æ„)
â”œâ”€â”€ train.sh                â† å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ TRAINING_README.md      â† è®­ç»ƒè¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ download_mnist.py       â† æ•°æ®ä¸‹è½½
â”œâ”€â”€ mnist_inference.cpp     â† HLSæ¨ç†æµ‹è¯•
â”œâ”€â”€ mnist_test.cpp          â† HLSåŸºç¡€æµ‹è¯•
â”œâ”€â”€ compare_models.py       â† æ¨¡å‹å¯¹æ¯”å·¥å…·
â”œâ”€â”€ visualize_mnist.py      â† å¯è§†åŒ–å·¥å…·
â”œâ”€â”€ data/                   â† MNISTæ•°æ®é›†
â””â”€â”€ weights/                â† å¯¼å‡ºçš„æƒé‡
```

## ğŸš€ å¿«é€Ÿä½¿ç”¨æŒ‡å—

### å®Œæ•´æµç¨‹

```bash
# 1. ä¸‹è½½æ•°æ®
make mnist_download

# 2. è®­ç»ƒæ¨¡å‹
make mnist_train

# 3. æµ‹è¯•æ¨ç†
make mnist_inference_full

# 4. HLSç»¼åˆ
make hls_synth
```

### ä»…è®­ç»ƒ

```bash
cd tests/mnist

# æ–¹æ³•1: ä½¿ç”¨Makefile
cd ../..
make mnist_train

# æ–¹æ³•2: ä½¿ç”¨è„šæœ¬
cd tests/mnist
./train.sh

# æ–¹æ³•3: ç›´æ¥Python
python3 train_model.py --epochs 60 --batch-size 32
```

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒè¾“å‡ºç¤ºä¾‹

```
======================================== MNIST CNN Training for Zynq 7020 (6-8-64 Architecture)
========================================
Architecture: Conv1[6] -> Conv2[8] -> FC1[64] -> FC2[10]
Expected parameters: ~10,000
Target accuracy: 90-93%
========================================

Using device: cuda

Loading MNIST data...
  Train: (60000, 1, 28, 28), Test: (10000, 1, 28, 28)
Applying data augmentation...
  After augmentation: (120000, 1, 28, 28)

Model parameters:
  Total: 10,666
  Trainable: 10,666

Training for 60 epochs...
----------------------------------------------------------------------
Epoch  1/60:  Train Loss: 0.8123, Acc: 73.45%  |  Test Loss: 0.4321, Acc: 86.12%  |  LR: 0.001500
Epoch 10/60:  Train Loss: 0.2034, Acc: 93.67%  |  Test Loss: 0.1756, Acc: 91.34%  |  LR: 0.001398
Epoch 20/60:  Train Loss: 0.1156, Acc: 96.12%  |  Test Loss: 0.1023, Acc: 92.78%  |  LR: 0.001090
  *** New best: 92.78% - Model saved ***
...
Epoch 50/60:  Train Loss: 0.0634, Acc: 97.89%  |  Test Loss: 0.0767, Acc: 93.45%  |  LR: 0.000123
  *** New best: 93.45% - Model saved ***
----------------------------------------------------------------------

Training complete!
Time elapsed: 0:38:23
Best test accuracy: 93.45%

======================================================================
Exporting weights for HLS...
======================================================================
  conv1_weights       : shape=(6, 1, 5, 5)    range=[-0.523,  0.498] size=     600 bytes
  conv1_bias          : shape=(6,)            range=[-0.234,  0.156] size=      24 bytes
  conv2_weights       : shape=(8, 6, 5, 5)    range=[-0.612,  0.589] size=    4800 bytes
  conv2_bias          : shape=(8,)            range=[-0.312,  0.267] size=      32 bytes
  fc1_weights         : shape=(64, 128)       range=[-0.789,  0.745] size=   32768 bytes
  fc1_bias            : shape=(64,)           range=[-0.445,  0.423] size=     256 bytes
  fc2_weights         : shape=(10, 64)        range=[-0.867,  0.834] size=    2560 bytes
  fc2_bias            : shape=(10,)           range=[-0.523,  0.489] size=      40 bytes

Weights exported to 'weights/' directory
======================================================================

======================================================================
SUCCESS! Model trained and weights exported.
======================================================================

Next steps:
  1. Run 'make hls_csim' to test in HLS C simulation
  2. Run 'make hls_synth' to synthesize for FPGA
  3. Run 'make mnist_inference_full' to test with exported weights
======================================================================
```

### å¯¼å‡ºçš„æƒé‡æ–‡ä»¶

```bash
$ ls -lh tests/mnist/weights/
total 40K
-rw-r--r-- 1 user user  24 Oct  4 22:00 conv1_bias.bin
-rw-r--r-- 1 user user 600 Oct  4 22:00 conv1_weights.bin
-rw-r--r-- 1 user user  32 Oct  4 22:00 conv2_bias.bin
-rw-r--r-- 1 user user 4.7K Oct  4 22:00 conv2_weights.bin
-rw-r--r-- 1 user user 256 Oct  4 22:00 fc1_bias.bin
-rw-r--r-- 1 user user 32K Oct  4 22:00 fc1_weights.bin
-rw-r--r-- 1 user user  40 Oct  4 22:00 fc2_bias.bin
-rw-r--r-- 1 user user 2.5K Oct  4 22:00 fc2_weights.bin
```

## ğŸ”„ ä»æ—§ç‰ˆæœ¬è¿ç§»

å¦‚æœæ‚¨ä¹‹å‰ä½¿ç”¨å…¶ä»–è®­ç»ƒè„šæœ¬ï¼Œè¯·ï¼š

1. **æ¸…ç†æ—§æƒé‡**:
```bash
make clean_mnist
```

2. **é‡æ–°è®­ç»ƒ**:
```bash
make mnist_train
```

3. **éªŒè¯æ–°æƒé‡**:
```bash
make mnist_inference_full
```

## âš™ï¸ HLSé›†æˆéªŒè¯

è®­ç»ƒå®Œæˆåï¼ŒéªŒè¯ä¸HLSçš„é›†æˆï¼š

### 1. Cä»¿çœŸ

```bash
make hls_csim
```

é¢„æœŸè¾“å‡º:
```
INFO: [HLS 200-10] Running csim...
Test passed!
Accuracy: 93.12% (close to Python 93.45%)
```

### 2. ç»¼åˆ

```bash
make hls_synth
```

é¢„æœŸèµ„æºä½¿ç”¨:
```
================================================================
== Performance Estimates
================================================================
+ Timing: 
    * Summary: 
    +--------+----------+----------+------------+
    |  Clock |  Target  | Estimated| Uncertainty|
    +--------+----------+----------+------------+
    |ap_clk  | 10.00 ns | 8.234 ns |   1.25 ns  |
    +--------+----------+----------+------------+

+ Latency: 
    * Summary: 
    +---------+---------+-----------+-----------+-----+-----+
    |  Latency (cycles) |   Latency (absolute)  | Interval  |
    +---------+---------+-----------+-----------+-----+-----+
    |  min    |   max   |    min    |    max    | min | max |
    +---------+---------+-----------+-----------+-----+-----+
    |   89456 |  89456  | 0.895 ms  | 0.895 ms  |  89457| 89457|
    +---------+---------+-----------+-----------+-----+-----+

================================================================
== Utilization Estimates
================================================================
* Summary: 
+-----------------+---------+-------+--------+-------+-----+
|       Name      | BRAM_18K| DSP48E|   FF   |  LUT  | URAM|
+-----------------+---------+-------+--------+-------+-----+
|DSP              |        -|      -|       -|      -|    -|
|Expression       |        -|      -|       0|      -|    -|
|FIFO             |        -|      -|       -|      -|    -|
|Instance         |        -|     89|   39234|  41567|    -|
|Memory           |       58|      -|       0|      0|    0|
|Multiplexer      |        -|      -|       -|    453|    -|
|Register         |        -|      -|     456|      -|    -|
+-----------------+---------+-------+--------+-------+-----+
|Total            |       58|     89|   39690|  42020|    0|
+-----------------+---------+-------+--------+-------+-----+
|Available        |      280|    220|  106400|  53200|    0|
+-----------------+---------+-------+--------+-------+-----+
|Utilization (%)  |       21|     40|      37|     79|    0|
+-----------------+---------+-------+--------+-------+-----+
```

**å…³é”®**: LUTä½¿ç”¨åº”è¯¥åœ¨ **79-90%** èŒƒå›´å†… âœ…

## ğŸ¯ æˆåŠŸæ ‡å‡†

- âœ… è®­ç»ƒç²¾åº¦: 90-93%
- âœ… HLS Cä»¿çœŸç²¾åº¦: ä¸Pythonå·®å¼‚<1%
- âœ… LUTä½¿ç”¨: <53,200 (100%)
- âœ… ç»¼åˆæˆåŠŸ: æ— é”™è¯¯
- âœ… æƒé‡æ–‡ä»¶: 8ä¸ª.binæ–‡ä»¶ï¼Œæ€»è®¡~40KB

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä¸»README](../../README.md) - é¡¹ç›®æ€»è§ˆ
- [TRAINING_README.md](TRAINING_README.md) - è®­ç»ƒè¯¦ç»†æ–‡æ¡£
- [FINAL_SOLUTION.md](../../FINAL_SOLUTION.md) - æœ€ç»ˆä¼˜åŒ–æ–¹æ¡ˆ
- [cnn_marco.h](../../src/cnn_marco.h) - HLSæ¶æ„å®šä¹‰

---

**æ—¥æœŸ**: 2025-10-04  
**ç‰ˆæœ¬**: 1.0 (6-8-64æ¶æ„)  
**çŠ¶æ€**: âœ… å°±ç»ª
